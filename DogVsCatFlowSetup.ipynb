{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dog Vs Cat: A CNN based Dog/Cat Classifer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, ELU\n",
    "from keras.layers.convolutional import Cropping2D, Convolution2D, MaxPooling2D\n",
    "from keras.layers.core import Lambda, Dense, Activation, Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "\n",
    "import logging\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 5.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Variables Initialazation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TRAIN_DATA_PATH_LIST = [\"./train\"]\n",
    "\n",
    "IMAGE_INPUT_SHAPE = (224, 224, 3)\n",
    "\n",
    "LABEL_LIST = sorted([\"dog\", \"cat\"])\n",
    "\n",
    "DO_VISUALIZE = True\n",
    "RUN_HOMEBREW_MODEL = False\n",
    "\n",
    "logger = logging.getLogger(\"DogVsCat\")  \n",
    "logger.setLevel(logging.DEBUG) \n",
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                filename='DogCat.log',\n",
    "                filemode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading, Analysis, Visualize and Encode Data Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def label_one_hot_encoding(labe_list):\n",
    "    encoder = LabelEncoder()\n",
    "    transfomed_label = encoder.fit_transform(labe_list)\n",
    "    one_hot_encoded_labels =  np_utils.to_categorical(transfomed_label)\n",
    "    one_hot_label_dict = {}\n",
    "    for i  in range(len(labe_list)):\n",
    "        one_hot_label_dict[labe_list[i]] = one_hot_encoded_labels[i] \n",
    "    \n",
    "    logger.info(\"one hot encoding for labels: \", one_hot_label_dict)\n",
    "    logger.info(one_hot_label_dict)\n",
    "    return one_hot_label_dict\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def load_samples(DATA_PATH, one_hot_encoding_dict):\n",
    "    \"\"\"\n",
    "    read all original data to a list, the element in the list is [one_hot_label, image_path]\n",
    "    return value is the list\n",
    "    \"\"\"\n",
    "    labels = one_hot_encoding_dict.keys()    \n",
    "    samples = [] # [one_hot_label, image_path]\n",
    "    temp_size = 0\n",
    "    for dir in DATA_PATH: \n",
    "        print(\"loading data from: \" + dir)\n",
    "        for key in labels:           \n",
    "            samples += [[one_hot_encoding_dict[key],file] for file in glob.glob(os.path.join(dir, key + '*.jpg'))]\n",
    "            temp_size = len(samples) - temp_size    \n",
    "            print(\"total \" + str(temp_size) + \" \" + key + \" images loaded.\")\n",
    "            logger.info(\"total \" + str(temp_size) + \" \" + key + \" images loaded.\")\n",
    "            temp_size = len(samples)\n",
    "        \n",
    "        print(\"total \" + str(temp_size) + \" raw data samples loaded.\")\n",
    "        logger.info(\"total \" + str(temp_size) + \" raw data samples loaded.\")\n",
    "        \n",
    "    return samples    \n",
    "\n",
    "\n",
    "\n",
    "def raw_data_analysis(raw_sample_list, one_hot_encoding_dict):\n",
    "    \"\"\"\n",
    "    image width/height counter, return value is a dict\n",
    "    \"\"\"    \n",
    "    inverse_one_hot_encoding_dict = {tuple(v): k for k, v in one_hot_encoding_dict.items()}\n",
    "    \n",
    "    print(inverse_one_hot_encoding_dict)\n",
    "    \n",
    "    image_size_counter = {}   \n",
    "    dimension_shape = [\"height\", \"width\"]\n",
    "    \n",
    "    for sample in raw_sample_list:   \n",
    "        label = inverse_one_hot_encoding_dict[tuple(sample[0])]\n",
    "        if label  not in image_size_counter:\n",
    "            image_size_counter[label]= {}\n",
    "            for i in range(len(dimension_shape)):\n",
    "                image_size_counter[label][dimension_shape[i]] = Counter() \n",
    "        \n",
    "        img = cv2.imread(sample[1])\n",
    "        for i in range(len(dimension_shape)):\n",
    "            image_size_counter[label][dimension_shape[i]][img.shape[i]] += 1\n",
    "\n",
    "            \n",
    "    for label in image_size_counter.keys():\n",
    "        for dim in dimension_shape:\n",
    "             print(\"most common \" + label + \" image \" + dim + \": \" , image_size_counter[label][dim].most_common(10))\n",
    "            \n",
    "\n",
    "    return image_size_counter\n",
    "\n",
    "\n",
    "\n",
    "def visualize_image_size_distribution(counter_dict):\n",
    "    \"\"\"\n",
    "    visualize_image width height distribution\n",
    "    \"\"\"  \n",
    "    data_label_list = list(counter_dict.keys())\n",
    "    dimension_list =   list(counter_dict[data_label_list[0]].keys())   \n",
    "    for dimension in dimension_list:    \n",
    "        f, ax = plt.subplots(1, 2)\n",
    "        for i in range(len(data_label_list)):\n",
    "            x = sorted(counter_dict[data_label_list[i]][dimension].keys())\n",
    "            y = [counter_dict[data_label_list[i]][dimension][j] for j in x]\n",
    "            ax[i].bar(x, y, width = 4, align='center', color= \"green\", alpha=0.4)            \n",
    "            ax[i].set_title(data_label_list[i] + \" image \" + dimension + \" distribution\")\n",
    "            ax[i].set_xlabel(\"size (in pixel)\")\n",
    "            ax[i].set_ylabel(\"count\")\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "\n",
    "    \n",
    "#one_hot_encoding_dict = label_one_hot_encoding(LABEL_LIST)\n",
    "#raw_samples = load_samples(TRAIN_DATA_PATH_LIST, one_hot_encoding_dict)\n",
    "#image_shape_counter = raw_data_analysis(raw_samples, one_hot_encoding_dict)\n",
    "#visualize_image_size_distribution(image_shape_counter)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Image Resize Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resize_image(image, output_shape = (100, 100, 3)):\n",
    "    \"\"\"\n",
    "    resize image to proper shape, the color channel will not be touched\n",
    "    \"\"\"      \n",
    "    shape = (output_shape[0], output_shape[1])    \n",
    "    resized_image = cv2.resize(image, shape)\n",
    "    return resized_image\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Functions to Setup Model From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def base_model_setup(input_shape, num_classes):    \n",
    "    \"\"\"\n",
    "    homebrew base model\n",
    "    \"\"\"     \n",
    "    model = Sequential()    \n",
    "    \n",
    "    model.add(Lambda(lambda x: x/127.5 -1., input_shape = input_shape))\n",
    "    model.add(Convolution2D(128,3,3)) #(32,3,3)\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(64,3,3))  #(32,3,3)  \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Convolution2D(32,3,3))  #(32,3,3)      \n",
    "    model.add(Activation('relu'))\n",
    "    model.add(MaxPooling2D((2, 2)))    \n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(16))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))    \n",
    "    model.add(Dense(num_classes))\n",
    "    #print(model.summary())\n",
    "    return model \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "def create_homebrew_models(input_shape = (224, 224, 3), num_classes = 2, output_activation_list = ['sigmoid'] , loss_function_list = ['categorical_crossentropy'], optimizer_list = [\"rmsprop\", \"adam\"]):\n",
    "    \"\"\"\n",
    "    create homebrew models from homebrew base model with different final activation functions and loss functions\n",
    "    \"\"\"      \n",
    "    model_dict = {}\n",
    "    for loss_function in loss_function_list:\n",
    "        for optimizer in optimizer_list:\n",
    "            for output_activation in output_activation_list:\n",
    "                model = base_model_setup(input_shape, num_classes)\n",
    "                model.add(Activation(output_activation))\n",
    "                \n",
    "                model.compile(loss = loss_function,  optimizer = optimizer , metrics = ['accuracy'])\n",
    "                name = \"activation=\" + output_activation + \"_loss=\" + loss_function + \"_optimizer=\" + optimizer\n",
    "                print(\"homebrew model generation: \" + name)\n",
    "                print(model.summary())\n",
    "                \n",
    "                model_dict[name] = model\n",
    "    \n",
    "    return model_dict    \n",
    "    \n",
    "    \n",
    "#home_brew_model_dict = create_homebrew_models(input_shape = (224, 224, 3), num_classes = 2, output_activation_list = ['sigmoid', 'softmax'] , loss_function_list = ['categorical_crossentropy' ], optimizer_list = [\"rmsprop\", \"adam\"])    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Setup Model from Pre-trainned Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def fine_tune_pretrained_model(input_shape = (224, 224, 3) , num_classes = 2, pre_trained_model_list = [\"ResNet\"]):\n",
    "    \"\"\"\n",
    "    create models based on pre-trainned model's front end\n",
    "    \"\"\"   \n",
    "    \n",
    "    model_dict = {}\n",
    "    \n",
    "    for model_type in pre_trained_model_list:\n",
    "        if model_type == \"ResNet\":\n",
    "            pre_trained_model = ResNet50(weights='imagenet', input_shape = input_shape, include_top = False)\n",
    "        elif model_type == \"VGG19\":\n",
    "            pre_trained_model = VGG19(weights='imagenet', input_shape = input_shape, include_top=False)\n",
    "        elif model_type == \"VGG16\":\n",
    "            pre_trained_model = VGG19(weights='imagenet', input_shape = input_shape, include_top=False)\n",
    "    \n",
    "        print(\"load pre-trainned model weight: \" + model_type)\n",
    "        \n",
    "        for layer in pre_trained_model.layers:\n",
    "            layer.trainable = False  # freeze the front-end weight of pre-trained model weight\n",
    "        \n",
    "        #pre_trained_model.summary()    \n",
    "        \n",
    "        # add back-end for current problem \n",
    "        x = pre_trained_model.output       \n",
    "        x = Flatten(name='flatten')(x)        \n",
    "        x = Dense(256, activation = \"relu\", name=\"fc256\") (x)        \n",
    "        x = Dense(64, activation = \"relu\", name=\"fc64\") (x)\n",
    "        x = Dropout(0.5) (x)    \n",
    "        x = Dense(num_classes, name=\"fc_output\") (x)\n",
    "        predictions =  Activation('softmax') (x)\n",
    "        \n",
    "        model = Model(input = pre_trained_model.input,  output=predictions)\n",
    "        model.compile(loss = 'categorical_crossentropy',  optimizer = \"rmsprop\" , metrics = ['accuracy'])\n",
    "        print(model_type)\n",
    "        print(model.summary())\n",
    "        model_dict[model_type] = model\n",
    "    \n",
    "    return model_dict\n",
    "\n",
    "\n",
    "#fine_tune_pretrained_model_dict =  fine_tune_pretrained_model(num_classes = 2, pre_trained_model_list = [\"VGG16\",\"VGG19\",\"ResNet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Sample Batch Generator for Model Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sample_generator(samples, batch_size=10):\n",
    "    \n",
    "    while True:\n",
    "        samples = shuffle(samples)\n",
    "        num_samples = len(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset + batch_size]\n",
    "            images = []\n",
    "            one_hot_labels = []\n",
    "            \n",
    "            for sample in batch_samples:\n",
    "                image = cv2.imread(sample[1])\n",
    "                image = resize_image(image, output_shape = IMAGE_INPUT_SHAPE)\n",
    "\n",
    "                images.append(image)\n",
    "                one_hot_labels.append(sample[0])\n",
    "                #plt.imshow(image)\n",
    "                #plt.show()\n",
    "            \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(one_hot_labels)\n",
    "            \n",
    "            #print(\"y_train\", y_train)\n",
    "            yield shuffle(X_train, y_train)\n",
    "\n",
    "    \n",
    "'''# generator unit test\n",
    "test_x, test_y = next(sample_generator(raw_samples, batch_size = 1))\n",
    "test_x = np.squeeze(test_x)\n",
    "print(test_x.shape)\n",
    "plt.imshow(cv2.cvtColor(test_x, cv2.COLOR_BGR2RGB))\n",
    "plt.title(str(test_y))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Fit History Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_fit_history_visualization(history, name):        \n",
    "        #  accuracy history\n",
    "        plt.plot(history.history['acc'])\n",
    "        plt.plot(history.history['val_acc'])\n",
    "        plt.title('model accuracy')\n",
    "        plt.ylabel('accuracy')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig(\"./resource/\" + name + '_accuracy.png')\n",
    "        plt.show()\n",
    "        # loss history\n",
    "        plt.plot(history.history['loss'])\n",
    "        plt.plot(history.history['val_loss'])\n",
    "        plt.title('model loss')\n",
    "        plt.ylabel('loss')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.savefig(\"./resource/\" + name + '_loss.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model training flow setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def flow_setup():\n",
    "    \n",
    "    one_hot_encoding_dict = label_one_hot_encoding(LABEL_LIST)\n",
    "    print(\"label is encoded by one-hot encoding: \", one_hot_encoding_dict)\n",
    "    \n",
    "    logger.info(one_hot_encoding_dict)\n",
    "    \n",
    "    raw_samples = load_samples(TRAIN_DATA_PATH_LIST, one_hot_encoding_dict)\n",
    "    print(\"raw sample loaded.\")\n",
    "    \n",
    "    image_shape_counter = raw_data_analysis(raw_samples, one_hot_encoding_dict)\n",
    "    \n",
    "    \n",
    "    if DO_VISUALIZE:\n",
    "        visualize_image_size_distribution(image_shape_counter)\n",
    "    \n",
    "    train_validation_samples, test_samples = train_test_split(raw_samples, test_size = 0.2, random_state = 42)\n",
    "    train_samples, validation_samples = train_test_split(train_validation_samples, test_size = 0.2, random_state = 42)\n",
    "    print()\n",
    "    print(\"train sample count: \", len(train_samples), \"\\nvalidation sample count: \", len(validation_samples), \"\\ntest sample count: \", len(test_samples))\n",
    "    \n",
    "    \n",
    "    train_generator = sample_generator(train_samples, batch_size = 100)\n",
    "    validation_generator = sample_generator(validation_samples, batch_size = 100)\n",
    "    test_generator = sample_generator(test_samples, batch_size = 100)\n",
    "\n",
    "\n",
    "    NUM_EPOCHS = 0\n",
    "    if RUN_HOMEBREW_MODEL:    \n",
    "        print(\"build home brew model...\")\n",
    "        model_dict =  create_homebrew_models(input_shape = IMAGE_INPUT_SHAPE, num_classes = 2, output_activation_list = ['sigmoid', 'softmax'] , loss_function_list = ['categorical_crossentropy' ], optimizer_list = [\"rmsprop\"])\n",
    "        NUM_EPOCHS = 10\n",
    "    else:\n",
    "        print(\"build model from pre-trainned model...\")\n",
    "        model_dict = fine_tune_pretrained_model(num_classes = 2, pre_trained_model_list = [\"VGG16\",\"VGG19\",\"ResNet\"])\n",
    "        NUM_EPOCHS = 3\n",
    "\n",
    "    print(\"model build finished.\")    \n",
    "    for name in model_dict.keys():\n",
    "        model = model_dict[name]\n",
    "        \n",
    "\n",
    "    \n",
    "        print(name + \" fitting started...\")\n",
    "        history_object = model.fit_generator(train_generator, samples_per_epoch= int(len(train_samples)), validation_data=validation_generator, nb_val_samples=len(validation_samples), nb_epoch=NUM_EPOCHS, verbose=1)\n",
    "        \n",
    "        if DO_VISUALIZE:\n",
    "            model_fit_history_visualization(history_object, name)\n",
    "        \n",
    "        score = model.evaluate_generator(test_generator, 1500, max_q_size=10, nb_worker=1, pickle_safe=False)\n",
    "        print(name + \" score:\", score)\n",
    "        model.save(\"./models/\" + name + \".h5\" )\n",
    "        print(\"model \" + name + \"saved.\")\n",
    "    \n",
    "\n",
    "flow_setup()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py3]",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
